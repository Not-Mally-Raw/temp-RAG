# LLM API Keys for Context Understanding
# Get your keys from:
# Groq: https://console.groq.com/keys (Free tier available)
# Cerebras: https://cloud.cerebras.ai/ (Free tier available)

# Groq API Key (Recommended - Fast and accurate)
GROQ_API_KEY=your_groq_api_key_here

# Cerebras API Key (Alternative)
CEREBRAS_API_KEY=your_cerebras_api_key_here

# Which LLM provider to use (groq or cerebras)
LLM_PROVIDER=groq

# Model selection (optional, will use defaults if not specified)
# Groq models: llama-3.3-70b-versatile, mixtral-8x7b-32768, gemma2-9b-it
# Cerebras models: llama3.1-70b, llama3.1-8b
LLM_MODEL=

# RAG Configuration
RAG_PERSIST_DIR=./universal_rag_db
RAG_CHUNK_SIZE=800
RAG_CHUNK_OVERLAP=100
RAG_EMBEDDING_MODEL=BAAI/bge-large-en-v1.5

# Processing Configuration
USE_LLM_CONTEXT=true
LLM_CONFIDENCE_THRESHOLD=0.6
MANUFACTURING_RELEVANCE_THRESHOLD=0.5
